# Synthetic ABR Environment

### Prerequisites
python 3.7, numpy, scipy, cython, tqdm, python-wget

### Environment interaction

To learn how to interact with the environment, read the code in `sample_interact.py`

### Trajectory generation

To log trajectories for offline learning, first use these commands:

```
cd cpolicies
make all
cd ..
```
If the compilation is successful, use this command:
```
python3 run_exp.py --output_folder OUTPUT_DIR
```
This command will likely take some time to execute (10-20 minutes). The outputs will also be large (~2GB).

The result is 6 numpy arrays in `OUTPUT_DIR`. Each include 2000 streaming sessions generated using one policy. Each session is 490 chunks in length.

For each chunk, there is an array of length (19 + 1 + 1 + 19 + 1). In order, this array consists of:
* An observation, with 19 dimensions
  * Last 5 throughput measurements
  * Last 5 chunk download times
  * Buffer level
  * Number of chunks left in video
  * Previous action
  * 6 file sizes for 6 possible encoding choices (the actions)
* The chosen action
* The reward in that state
* The next observation, with 19 dimensions
* Whether the session is over or not (always 1 at the end of the 490 chunks and 0 elsewhere)
